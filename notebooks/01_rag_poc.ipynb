{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36afda5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n",
      "Project root: /Users/edsonflores/Documents/vsc/Freelance/dev-chatbot-rag\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "\"\"\"\n",
    "Research Paper Navigator - RAG POC\n",
    "===================================\n",
    "Testing core functionality:\n",
    "1. PDF ingestion and parsing\n",
    "2. Chunking strategies (fixed, semantic, recursive)\n",
    "3. Embedding and vector storage\n",
    "4. Retrieval (dense, sparse, hybrid)\n",
    "5. Reranking\n",
    "6. Generation with context\n",
    "7. Evaluation metrics\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path (for later when we modularize)\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root / \"src\"))\n",
    "\n",
    "# Core imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# LangChain\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    ")\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# BM25 for hybrid search\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Utilities\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "932b707f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Data directories:\n",
      "  Raw PDFs: /Users/edsonflores/Documents/vsc/Freelance/dev-chatbot-rag/data/raw\n",
      "  Processed: /Users/edsonflores/Documents/vsc/Freelance/dev-chatbot-rag/data/processed\n",
      "  Vector Store: /Users/edsonflores/Documents/vsc/Freelance/dev-chatbot-rag/data/vector_store\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configuration\n",
    "\"\"\"\n",
    "Configuration for the RAG system\n",
    "\"\"\"\n",
    "\n",
    "class Config:\n",
    "    # Paths\n",
    "    DATA_DIR = project_root / \"data\"\n",
    "    RAW_DIR = DATA_DIR / \"raw\"\n",
    "    PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "    VECTOR_STORE_DIR = DATA_DIR / \"vector_store\"\n",
    "    \n",
    "    # Ensure directories exist\n",
    "    RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    VECTOR_STORE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Model configurations\n",
    "    EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"  # Fast, 384 dims\n",
    "    # Alternative: \"BAAI/bge-large-en-v1.5\"  # Better quality, 1024 dims\n",
    "    \n",
    "    LLM_MODEL = \"llama3.1:8b\"\n",
    "    LLM_TEMPERATURE = 0.1  # Lower for factual responses\n",
    "    \n",
    "    # Chunking configurations\n",
    "    CHUNK_SIZE = 512\n",
    "    CHUNK_OVERLAP = 128\n",
    "    \n",
    "    # Retrieval configurations\n",
    "    TOP_K = 5  # Number of chunks to retrieve\n",
    "    RERANK_TOP_K = 3  # After reranking\n",
    "    \n",
    "    # Collection name for ChromaDB\n",
    "    COLLECTION_NAME = \"research_papers\"\n",
    "\n",
    "config = Config()\n",
    "\n",
    "print(\"üìÅ Data directories:\")\n",
    "print(f\"  Raw PDFs: {config.RAW_DIR}\")\n",
    "print(f\"  Processed: {config.PROCESSED_DIR}\")\n",
    "print(f\"  Vector Store: {config.VECTOR_STORE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d8bc2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF parsing functions ready!\n",
      "\n",
      "To test, add a PDF to: /Users/edsonflores/Documents/vsc/Freelance/dev-chatbot-rag/data/raw\n",
      "Then run: docs = load_pdf_pymupdf('data/raw/your_paper.pdf')\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Helper Functions for PDF Parsing\n",
    "\"\"\"\n",
    "Different PDF parsing strategies to compare\n",
    "\"\"\"\n",
    "\n",
    "def load_pdf_pypdf(pdf_path: str) -> List[Dict]:\n",
    "    \"\"\"Basic PDF loading with PyPDF\"\"\"\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "def load_pdf_pymupdf(pdf_path: str) -> List[Dict]:\n",
    "    \"\"\"Better quality PDF loading with PyMuPDF\"\"\"\n",
    "    loader = PyMuPDFLoader(pdf_path)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "def extract_metadata(document) -> Dict:\n",
    "    \"\"\"Extract useful metadata from document\"\"\"\n",
    "    metadata = document.metadata.copy()\n",
    "    \n",
    "    # Add extraction timestamp\n",
    "    metadata['extracted_at'] = datetime.now().isoformat()\n",
    "    \n",
    "    # Character count\n",
    "    metadata['char_count'] = len(document.page_content)\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "# Test with a sample PDF (you'll add PDFs to data/raw/)\n",
    "print(\"PDF parsing functions ready!\")\n",
    "print(\"\\nTo test, add a PDF to:\", config.RAW_DIR)\n",
    "print(\"Then run: docs = load_pdf_pymupdf('data/raw/your_paper.pdf')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb6ee6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chunking functions ready!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Chunking Strategies\n",
    "\"\"\"\n",
    "Compare different chunking strategies\n",
    "\"\"\"\n",
    "\n",
    "def chunk_fixed_size(documents, chunk_size=512, overlap=128):\n",
    "    \"\"\"Fixed-size chunking\"\"\"\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=overlap,\n",
    "        separator=\"\\n\",\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    return chunks\n",
    "\n",
    "def chunk_recursive(documents, chunk_size=512, overlap=128):\n",
    "    \"\"\"Recursive chunking - better for preserving context\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    return chunks\n",
    "\n",
    "def analyze_chunks(chunks):\n",
    "    \"\"\"Analyze chunk statistics\"\"\"\n",
    "    lengths = [len(chunk.page_content) for chunk in chunks]\n",
    "    \n",
    "    stats = {\n",
    "        'total_chunks': len(chunks),\n",
    "        'avg_length': np.mean(lengths),\n",
    "        'std_length': np.std(lengths),\n",
    "        'min_length': np.min(lengths),\n",
    "        'max_length': np.max(lengths),\n",
    "    }\n",
    "    \n",
    "    return stats, lengths\n",
    "\n",
    "def visualize_chunk_distribution(lengths, title=\"Chunk Length Distribution\"):\n",
    "    \"\"\"Visualize chunk size distribution\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(lengths, bins=30, edgecolor='black', alpha=0.7)\n",
    "    plt.axvline(np.mean(lengths), color='red', linestyle='--', \n",
    "                label=f'Mean: {np.mean(lengths):.0f}')\n",
    "    plt.xlabel('Chunk Length (characters)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Chunking functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b410a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/3n849rn554l15tgrg12vm59m0000gn/T/ipykernel_58301/402174243.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c0f36f8a1b4686ae281f7df32ee53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99cdfad25130426ea15e7ff7454996e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03129cd8219464a8ca659151ec46431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8879233143cc416491fd1562d20990a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bcda3f709ad4bd4a2fdb52fa372d82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e40d02219924ed69d36c1bf15924b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d26b7c79806448886ce4a7d33a3c2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed96170f22c4667b0c0c3a72a000ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62f9cdded764ca6a5fba5a54c8fd3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d506b5a8da4e37a5b1bdebd3f7a3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc2002164aa4b30be1e7a795a3192ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embedding model loaded: sentence-transformers/all-MiniLM-L6-v2\n",
      "   Dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Initialize Embeddings and Vector Store\n",
    "\"\"\"\n",
    "Setup embedding model and vector database\n",
    "\"\"\"\n",
    "\n",
    "# Initialize embedding model\n",
    "print(\"Loading embedding model...\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=config.EMBEDDING_MODEL,\n",
    "    model_kwargs={'device': 'cpu'},  # Use 'mps' for M4 GPU if supported\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Embedding model loaded: {config.EMBEDDING_MODEL}\")\n",
    "print(f\"   Dimension: {len(embeddings.embed_query('test'))}\")\n",
    "\n",
    "def create_vector_store(chunks, collection_name=None):\n",
    "    \"\"\"Create ChromaDB vector store from chunks\"\"\"\n",
    "    if collection_name is None:\n",
    "        collection_name = config.COLLECTION_NAME\n",
    "    \n",
    "    print(f\"Creating vector store with {len(chunks)} chunks...\")\n",
    "    \n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        collection_name=collection_name,\n",
    "        persist_directory=str(config.VECTOR_STORE_DIR)\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Vector store created: {collection_name}\")\n",
    "    return vectorstore\n",
    "\n",
    "def load_vector_store(collection_name=None):\n",
    "    \"\"\"Load existing vector store\"\"\"\n",
    "    if collection_name is None:\n",
    "        collection_name = config.COLLECTION_NAME\n",
    "    \n",
    "    vectorstore = Chroma(\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=str(config.VECTOR_STORE_DIR)\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Vector store loaded: {collection_name}\")\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3cad3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dense retrieval ready!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Dense Retrieval (Vector Search)\n",
    "\"\"\"\n",
    "Dense retrieval using embeddings\n",
    "\"\"\"\n",
    "\n",
    "def dense_retrieval(vectorstore, query: str, k: int = 5):\n",
    "    \"\"\"Retrieve using dense embeddings\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Similarity search\n",
    "    results = vectorstore.similarity_search_with_score(query, k=k)\n",
    "    \n",
    "    retrieval_time = time.time() - start_time\n",
    "    \n",
    "    # Format results\n",
    "    formatted_results = []\n",
    "    for doc, score in results:\n",
    "        formatted_results.append({\n",
    "            'content': doc.page_content,\n",
    "            'metadata': doc.metadata,\n",
    "            'score': float(score),\n",
    "            'method': 'dense'\n",
    "        })\n",
    "    \n",
    "    return formatted_results, retrieval_time\n",
    "\n",
    "print(\"‚úÖ Dense retrieval ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea6fac08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ BM25 retriever ready!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Sparse Retrieval (BM25)\n",
    "\"\"\"\n",
    "Sparse retrieval using BM25 for comparison/hybrid\n",
    "\"\"\"\n",
    "\n",
    "class BM25Retriever:\n",
    "    def __init__(self, chunks):\n",
    "        \"\"\"Initialize BM25 with document chunks\"\"\"\n",
    "        self.chunks = chunks\n",
    "        \n",
    "        # Tokenize documents\n",
    "        self.tokenized_docs = [\n",
    "            doc.page_content.lower().split() \n",
    "            for doc in chunks\n",
    "        ]\n",
    "        \n",
    "        # Create BM25 index\n",
    "        self.bm25 = BM25Okapi(self.tokenized_docs)\n",
    "        print(f\"‚úÖ BM25 index created with {len(chunks)} documents\")\n",
    "    \n",
    "    def search(self, query: str, k: int = 5):\n",
    "        \"\"\"Search using BM25\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Tokenize query\n",
    "        tokenized_query = query.lower().split()\n",
    "        \n",
    "        # Get scores\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        \n",
    "        # Get top-k indices\n",
    "        top_k_idx = np.argsort(scores)[::-1][:k]\n",
    "        \n",
    "        retrieval_time = time.time() - start_time\n",
    "        \n",
    "        # Format results\n",
    "        results = []\n",
    "        for idx in top_k_idx:\n",
    "            results.append({\n",
    "                'content': self.chunks[idx].page_content,\n",
    "                'metadata': self.chunks[idx].metadata,\n",
    "                'score': float(scores[idx]),\n",
    "                'method': 'bm25'\n",
    "            })\n",
    "        \n",
    "        return results, retrieval_time\n",
    "\n",
    "print(\"‚úÖ BM25 retriever ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d77dc3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Hybrid retrieval ready!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Hybrid Retrieval\n",
    "\"\"\"\n",
    "Combine dense and sparse retrieval\n",
    "\"\"\"\n",
    "\n",
    "def hybrid_retrieval(\n",
    "    vectorstore, \n",
    "    bm25_retriever, \n",
    "    query: str, \n",
    "    k: int = 5,\n",
    "    alpha: float = 0.5  # Weight for dense vs sparse\n",
    "):\n",
    "    \"\"\"\n",
    "    Hybrid search combining dense and sparse retrieval\n",
    "    alpha: weight for dense (1-alpha for sparse)\n",
    "    \"\"\"\n",
    "    # Get results from both methods\n",
    "    dense_results, _ = dense_retrieval(vectorstore, query, k=k*2)\n",
    "    sparse_results, _ = bm25_retriever.search(query, k=k*2)\n",
    "    \n",
    "    # Normalize scores to [0, 1]\n",
    "    def normalize_scores(results):\n",
    "        scores = [r['score'] for r in results]\n",
    "        if max(scores) == min(scores):\n",
    "            return results\n",
    "        \n",
    "        normalized = []\n",
    "        for r in results:\n",
    "            norm_score = (r['score'] - min(scores)) / (max(scores) - min(scores))\n",
    "            r_copy = r.copy()\n",
    "            r_copy['score'] = norm_score\n",
    "            normalized.append(r_copy)\n",
    "        return normalized\n",
    "    \n",
    "    dense_results = normalize_scores(dense_results)\n",
    "    sparse_results = normalize_scores(sparse_results)\n",
    "    \n",
    "    # Combine with Reciprocal Rank Fusion (RRF)\n",
    "    combined_scores = {}\n",
    "    \n",
    "    for rank, result in enumerate(dense_results, 1):\n",
    "        content = result['content']\n",
    "        combined_scores[content] = alpha / (60 + rank)\n",
    "    \n",
    "    for rank, result in enumerate(sparse_results, 1):\n",
    "        content = result['content']\n",
    "        if content in combined_scores:\n",
    "            combined_scores[content] += (1 - alpha) / (60 + rank)\n",
    "        else:\n",
    "            combined_scores[content] = (1 - alpha) / (60 + rank)\n",
    "    \n",
    "    # Sort by combined score\n",
    "    sorted_results = sorted(\n",
    "        combined_scores.items(), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True\n",
    "    )[:k]\n",
    "    \n",
    "    # Format results\n",
    "    hybrid_results = []\n",
    "    for content, score in sorted_results:\n",
    "        # Find original result for metadata\n",
    "        orig = next((r for r in dense_results + sparse_results \n",
    "                    if r['content'] == content), None)\n",
    "        \n",
    "        hybrid_results.append({\n",
    "            'content': content,\n",
    "            'metadata': orig['metadata'] if orig else {},\n",
    "            'score': score,\n",
    "            'method': 'hybrid'\n",
    "        })\n",
    "    \n",
    "    return hybrid_results\n",
    "\n",
    "print(\"‚úÖ Hybrid retrieval ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed9905bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Ollama LLM...\n",
      "‚úÖ LLM Response: LLM is ready!\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Initialize LLM\n",
    "\"\"\"\n",
    "Setup local LLM with Ollama\n",
    "\"\"\"\n",
    "\n",
    "print(\"Initializing Ollama LLM...\")\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=config.LLM_MODEL,\n",
    "    temperature=config.LLM_TEMPERATURE,\n",
    ")\n",
    "\n",
    "# Test the LLM\n",
    "test_response = llm.invoke(\"Say 'LLM is ready!' and nothing else.\")\n",
    "print(f\"‚úÖ LLM Response: {test_response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cace684e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG chain functions ready!\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: RAG Chain with Custom Prompt\n",
    "\"\"\"\n",
    "Create RAG chain for Q&A\n",
    "\"\"\"\n",
    "\n",
    "# Custom prompt for research papers\n",
    "RAG_PROMPT_TEMPLATE = \"\"\"You are an AI assistant helping researchers understand academic papers.\n",
    "\n",
    "Use the following pieces of context from research papers to answer the question. \n",
    "If you don't know the answer based on the context, say so - don't make up information.\n",
    "\n",
    "When possible, mention which paper or section the information comes from.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer (be concise but comprehensive):\"\"\"\n",
    "\n",
    "RAG_PROMPT = PromptTemplate(\n",
    "    template=RAG_PROMPT_TEMPLATE,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "def create_rag_chain(vectorstore):\n",
    "    \"\"\"Create RAG QA chain\"\"\"\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vectorstore.as_retriever(search_kwargs={\"k\": config.TOP_K}),\n",
    "        chain_type_kwargs={\"prompt\": RAG_PROMPT},\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    \n",
    "    return qa_chain\n",
    "\n",
    "def query_rag(qa_chain, question: str):\n",
    "    \"\"\"Query the RAG system\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    \n",
    "    query_time = time.time() - start_time\n",
    "    \n",
    "    return {\n",
    "        'question': question,\n",
    "        'answer': result['result'],\n",
    "        'source_documents': result['source_documents'],\n",
    "        'query_time': query_time\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ RAG chain functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8f0763e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Evaluation functions ready!\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Evaluation Metrics\n",
    "\"\"\"\n",
    "Simple evaluation metrics for RAG quality\n",
    "\"\"\"\n",
    "\n",
    "def calculate_faithfulness(answer: str, context_docs: List) -> Dict:\n",
    "    \"\"\"\n",
    "    Simple faithfulness check - are claims in answer supported by context?\n",
    "    (In production, you'd use an LLM-as-judge for this)\n",
    "    \"\"\"\n",
    "    context_text = \" \".join([doc.page_content for doc in context_docs])\n",
    "    \n",
    "    # Simple heuristic: check if answer phrases appear in context\n",
    "    answer_sentences = answer.split('. ')\n",
    "    \n",
    "    supported_count = 0\n",
    "    for sentence in answer_sentences:\n",
    "        # Check if key phrases from sentence appear in context\n",
    "        words = sentence.lower().split()\n",
    "        # Consider 3-word phrases\n",
    "        for i in range(len(words) - 2):\n",
    "            phrase = ' '.join(words[i:i+3])\n",
    "            if phrase in context_text.lower():\n",
    "                supported_count += 1\n",
    "                break\n",
    "    \n",
    "    faithfulness_score = supported_count / len(answer_sentences) if answer_sentences else 0\n",
    "    \n",
    "    return {\n",
    "        'faithfulness_score': faithfulness_score,\n",
    "        'total_sentences': len(answer_sentences),\n",
    "        'supported_sentences': supported_count\n",
    "    }\n",
    "\n",
    "def evaluate_retrieval(query: str, retrieved_docs: List, relevant_doc_ids: List = None):\n",
    "    \"\"\"\n",
    "    Evaluate retrieval quality\n",
    "    (In real scenario, you'd have ground truth relevant docs)\n",
    "    \"\"\"\n",
    "    # For now, just analyze retrieved docs\n",
    "    stats = {\n",
    "        'num_retrieved': len(retrieved_docs),\n",
    "        'avg_doc_length': np.mean([len(doc.page_content) for doc in retrieved_docs]),\n",
    "        'unique_sources': len(set([doc.metadata.get('source', 'unknown') \n",
    "                                   for doc in retrieved_docs]))\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "print(\"‚úÖ Evaluation functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1090b1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading sample papers...\n",
      "  Downloading attention_is_all_you_need.pdf...\n",
      "  ‚úÖ Saved to /Users/edsonflores/Documents/vsc/Freelance/dev-chatbot-rag/data/raw/attention_is_all_you_need.pdf\n",
      "  Downloading bert.pdf...\n",
      "  ‚úÖ Saved to /Users/edsonflores/Documents/vsc/Freelance/dev-chatbot-rag/data/raw/bert.pdf\n",
      "\n",
      "‚úÖ Sample papers ready!\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Sample Test Data Generator\n",
    "\"\"\"\n",
    "Helper to download sample research papers for testing\n",
    "\"\"\"\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "def download_sample_papers():\n",
    "    \"\"\"\n",
    "    Download sample papers from ArXiv\n",
    "    \"\"\"\n",
    "    sample_papers = {\n",
    "        'attention_is_all_you_need.pdf': \n",
    "            'https://arxiv.org/pdf/1706.03762.pdf',  # Transformer paper\n",
    "        'bert.pdf': \n",
    "            'https://arxiv.org/pdf/1810.04805.pdf',  # BERT paper\n",
    "    }\n",
    "    \n",
    "    print(\"Downloading sample papers...\")\n",
    "    for filename, url in sample_papers.items():\n",
    "        filepath = config.RAW_DIR / filename\n",
    "        if not filepath.exists():\n",
    "            print(f\"  Downloading {filename}...\")\n",
    "            urllib.request.urlretrieve(url, filepath)\n",
    "            print(f\"  ‚úÖ Saved to {filepath}\")\n",
    "        else:\n",
    "            print(f\"  ‚è≠Ô∏è  {filename} already exists\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Sample papers ready!\")\n",
    "    return list(sample_papers.keys())\n",
    "\n",
    "# Uncomment to download\n",
    "downloaded_files = download_sample_papers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "539c0161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Complete testing pipeline ready!\n",
      "\n",
      "üìù Usage:\n",
      "results = test_rag_pipeline(\n",
      "    pdf_path='data/raw/your_paper.pdf',\n",
      "    test_queries=[\n",
      "        'What is the main contribution of this paper?',\n",
      "        'What datasets were used?',\n",
      "        'What are the key findings?'\n",
      "    ]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Complete RAG Testing Pipeline\n",
    "\"\"\"\n",
    "End-to-end testing workflow\n",
    "\"\"\"\n",
    "\n",
    "def test_rag_pipeline(pdf_path: str, test_queries: List[str]):\n",
    "    \"\"\"\n",
    "    Complete RAG pipeline test\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'pdf_path': pdf_path,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'queries': []\n",
    "    }\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"RAG PIPELINE TEST\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Step 1: Load PDF\n",
    "    print(\"\\nüìÑ Step 1: Loading PDF...\")\n",
    "    documents = load_pdf_pymupdf(pdf_path)\n",
    "    print(f\"   Loaded {len(documents)} pages\")\n",
    "    \n",
    "    # Step 2: Chunk documents\n",
    "    print(\"\\n‚úÇÔ∏è  Step 2: Chunking documents...\")\n",
    "    chunks = chunk_recursive(documents)\n",
    "    stats, lengths = analyze_chunks(chunks)\n",
    "    print(f\"   Created {stats['total_chunks']} chunks\")\n",
    "    print(f\"   Avg length: {stats['avg_length']:.0f} chars\")\n",
    "    \n",
    "    visualize_chunk_distribution(lengths)\n",
    "    \n",
    "    # Step 3: Create vector store\n",
    "    print(\"\\nüîç Step 3: Creating vector store...\")\n",
    "    vectorstore = create_vector_store(chunks)\n",
    "    \n",
    "    # Step 4: Initialize BM25\n",
    "    print(\"\\nüìä Step 4: Initializing BM25...\")\n",
    "    bm25_retriever = BM25Retriever(chunks)\n",
    "    \n",
    "    # Step 5: Create RAG chain\n",
    "    print(\"\\n‚öôÔ∏è  Step 5: Creating RAG chain...\")\n",
    "    qa_chain = create_rag_chain(vectorstore)\n",
    "    \n",
    "    # Step 6: Test queries\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"TESTING QUERIES\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"\\nüîé Query {i}: {query}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Get answer\n",
    "        result = query_rag(qa_chain, query)\n",
    "        \n",
    "        print(f\"\\nüí° Answer:\\n{result['answer']}\")\n",
    "        print(f\"\\n‚è±Ô∏è  Time: {result['query_time']:.2f}s\")\n",
    "        \n",
    "        # Evaluate\n",
    "        faithfulness = calculate_faithfulness(\n",
    "            result['answer'], \n",
    "            result['source_documents']\n",
    "        )\n",
    "        print(f\"\\nüìà Faithfulness: {faithfulness['faithfulness_score']:.2f}\")\n",
    "        \n",
    "        print(f\"\\nüìö Sources ({len(result['source_documents'])}):\")\n",
    "        for j, doc in enumerate(result['source_documents'], 1):\n",
    "            preview = doc.page_content[:100] + \"...\"\n",
    "            print(f\"   {j}. {preview}\")\n",
    "        \n",
    "        results['queries'].append({\n",
    "            'query': query,\n",
    "            'answer': result['answer'],\n",
    "            'time': result['query_time'],\n",
    "            'faithfulness': faithfulness['faithfulness_score'],\n",
    "            'num_sources': len(result['source_documents'])\n",
    "        })\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Complete testing pipeline ready!\")\n",
    "print(\"\\nüìù Usage:\")\n",
    "print(\"results = test_rag_pipeline(\")\n",
    "print(\"    pdf_path='data/raw/your_paper.pdf',\")\n",
    "print(\"    test_queries=[\")\n",
    "print(\"        'What is the main contribution of this paper?',\")\n",
    "print(\"        'What datasets were used?',\")\n",
    "print(\"        'What are the key findings?'\")\n",
    "print(\"    ]\")\n",
    "print(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45b11825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RAG PIPELINE TEST\n",
      "======================================================================\n",
      "\n",
      "üìÑ Step 1: Loading PDF...\n",
      "   Loaded 16 pages\n",
      "\n",
      "‚úÇÔ∏è  Step 2: Chunking documents...\n",
      "   Created 169 chunks\n",
      "   Avg length: 472 chars\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0kAAAHWCAYAAACi1sL/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNz0lEQVR4nO3dCXQUVdbA8dvZSUhYE0BZFUQWgQE3BhUFlEUZEEZxYUBEHRWVRdHBcUOdAfWTRUVglHVQURTcQdlRWYZFRZFBQRaVLYAQEshe37mP6aY6JJBOulPdnf/vnDLV1d2vX70q2rr93rvlsizLEgAAAACAEXHiDwAAAABAESQBAAAAgA1BEgAAAADYECQBAAAAgA1BEgAAAADYECQBAAAAgA1BEgAAAADYECQBAAAAgA1BEgAAAADYECQBQBlyuVxy3333OfLZTz31lPn8AwcOSHly5ZVXSvPmzcv0M7Wdtb0DbdmyZeaz9K8T+7tjxw7z+dOnTy+TzwOAskKQBAB+sG3bNvnrX/8q55xzjsTFxUlSUpK0a9dOxo8fL8ePH5dQpxfBejG8bt06CUa7d+82Qck333zj97Lr169v9l2XiIgIqVy5slxwwQVy1113yZo1a/z2OW+++aaMGzdOglEw1w0AAiEqIKUCQDnyySefyA033CCxsbHSr18/8yt+dna2fPnllzJ8+HDZtGmT/Otf/3K6mmFNg6SRI0eagKZVq1Z+L1/LfPDBB8360aNHZfPmzTJnzhx57bXXZOjQoTJmzBiv12tgHBUV5XMg8v3338uQIUOK/Z4rrrjCfFZMTIwEUlF1q1evnvn86OjogH4+AJQ1giQAKIXt27fLTTfdZC4WlyxZIrVq1fI8N2jQINm6dasJohDazj77bOnbt6/Xtueee05uueUWGTt2rDRq1Ejuuecez3PamxhImZmZJjDSnq1Af9bpaO+ak58PAIHCcDsAKIXnn39e0tPTZcqUKV4BklvDhg1l8ODBp2x///33TY+T9j41a9ZMFixY4PX8bbfdZnpFippXVNg8pzOVWZidO3eaOur79u3bJ6X122+/ye233y41atTw1GPq1KmFzqN555135B//+IfUrl3bXGh37NjRBJUFTZgwwQxjrFChglx88cXyxRdfmHk3urjLu+iii8z6gAEDPEPjCs6T+eGHH+Sqq66S+Ph4E/TosSsNrc+///1vqVq1qtkPy7KKnJOkvU/aC6PHVNslJSVFrr76atmwYYN5XvdFg2k9Hu76u4+/u71mz54tjz32mKm77kNaWlqhc5Lc1q9fL3/84x9NPRs0aCCTJk0qdAilziuyK1jm6epW1Jwk/cHg8ssvl4SEBDM8sUePHqb3rbBzWY+5nu/6ukqVKpljeOzYsRIfFwDwB3qSAKAUPvroI3MBrxejxaXD8ObOnSv33nuvJCYmyksvvSS9e/eWXbt2SbVq1UpUj5KUqfOoOnToYC7yFy5cKNWrV5fS0CDr0ksv9QRtycnJMn/+fBk4cKC5oC84VGv06NGmJ+Shhx6SI0eOmKDl1ltv9ZrnM3HiRFOWXnDrsDa9KO/Zs6dUqVLFBFeqSZMm8vTTT8sTTzxh5gnpa5X9mPz+++/SpUsX6dWrl9x4443y7rvvyiOPPGLmFnXt2rXE+1yxYkW5/vrrTZCsQZgGhYW5++67zWfqvjRt2lQOHjxojpkGDq1bt5a///3vpg1+/fVX0zPlLtvumWeeMb1H2l5ZWVmnHWKn+9utWzezrzfffLMJSLWnS9+jQawvilM3u0WLFpk21X8XGgjpcLyXX37ZzNHToLBg8K911CBu1KhR5vnXX3/dBJHaUwcAjrEAACVy5MgR7TqwevToUez36OtjYmKsrVu3erZ9++23ZvvLL7/s2da/f3+rXr16p7z/ySefNK8tSZnu96amplqbN2+2zjrrLOuiiy6yDh06dMZ6T5s2zbx37dq1Rb5m4MCBVq1atawDBw54bb/pppusSpUqWceOHTOPly5daspq0qSJlZWV5Xnd+PHjzfbvvvvOPNbnqlWrZuqYk5Pjed306dPN69q3b+/ZpvXSbVrPgvR1+tzMmTM927TsmjVrWr179z7jvutxuPbaa4t8fuzYsab8Dz74wLNNH2t7u+n+Dxo06LSfo59R2DF3t9c555zjacOCz+nfgvv74osveu1vq1atrJSUFCs7O9vrmG7fvv2MZRZVN31vwXZ3f87Bgwe9zseIiAirX79+p5yPt99+u1eZ119/vTnuAOAkhtsBQAlp74jSnhtfdOrUSc4991zP4xYtWphseD///HOJ6+JLmToBv3379uYXff3VX3tlSkvjgvfee0+6d+9u1jXNuHvp3Lmz6YlwDy1z02FV9t4Qdw+Qu86aSU97XO68806vJAja2+RrnbXnwz6nSD9Xh+6Vps3tZbuH1BVFh5JpD5kmmCip/v37m6FzxaHtpdkW7furj/fv32+G4QXKnj17TIZBHT6nPZT281GHF3766aeF9rLZ6Xmgx9397wsAnECQBAAlpEHImS6OC1O3bt1TtulFvw6RKilfytRARgO7zz77zLMPpZWamiqHDx82Wfx0mJ190WBI6QX66ersDnzcddY5MErnTBUMAAqbr3U6OjSv4Fyu0ra5m85JO1OwrEMJNTitU6eOCc50GJqvAZoOSSuus846y8wHsjvvvPPM34JzkPzJfcwaN258ynM6LFKD5oyMDJ/OAwBwAkESAJSQBhh6MaoXv76IjIwsdHvBif+FycvLK3GZbjpXSecjvfHGG+Iv+fn55q/21uj8psIWnZNS0jqXViA/y338CwZzBefdaFCkc3P0nHnhhRfM/CWds1Vcxe1FKi5fz7FAKcvzAACKi8QNAFAK1113nek9WbVqlbRt29Zv5eqv6dozU9Qv9aWhF+jaG+NO8qBprEtLe4y0LL3A1qF//qBp1ZVmP9OsdG65ubmmN0SHcJ3pgj/QtBdp3rx5podIe0pOR7Mfapvror1qmrBBs+K5E0f4cx90WJ/22Nh7k3788Ufz190L5+6xKXieFXaOFbdu7mO2ZcuWU57773//a5KDFOzhAoBgRE8SAJTCww8/bC767rjjjkJTaGuPzfjx430uV+cX6TyejRs3es330Avy0tILXg3s/vznP5t5Lh9++KFfegO0h0rnJRXWs6bD8Xx14YUXmsx8esNWDYzctAes4FAs94V3YYFloGjWtr/85S9y6NAhkwHudD0zeiztNHub9ihpljr7PhR8XUlpe02ePNnzWG9urI81mG3Tpo3Z5p7DtmLFCq+6Fnbj4+LWTQNBvfHujBkzvI6FnhOff/65ybgHAKGAniQAKAW90HzzzTelT58+piehX79+5p5DelG6cuVKmTNnjpnE7iu9Qa2mqNb00g888IC5b4ymw9Z5JQUTIJSEpt6eNWuWSaetQ8F0Qr2mAz8TvedRYfdf0ntBaUrvpUuXyiWXXGKSLWiqaw0gtL6aIELXfaHJBnTuzv3332/qpvXUHiS9J4+2uz0o0ceaHEHvBaQ9WnpRr/XwZR7Pme7/pO3l7j3SdN96bPfu3SsPPvigV5KEgnTOms6J0qC0ZcuWJtGDtsfatWvlxRdf9LxOg5e3335bhg0bZu77pK/T+WMloQGYptDW9tJzRsvVhAoaAEVHR5vX6HA/Tdk+YsQIc2w00YLei8kekJakbtpTqb1j2rOq6d/dKcD1Hkj2e0cBQFBzNLceAISJH3/80brzzjut+vXrm3TciYmJVrt27UwK7szMTM/r9Gu3sFTQml5Z037bff7551bz5s1NeY0bN7ZmzZpVZArw4pRpTwHupimlNWV0xYoVrdWrVxe5f+500UUtv/zyi3ndvn37TF3q1KljRUdHmzTbHTt2tP71r3+dkmJ6zpw5Z0wnrV566SWzL7GxsdbFF19sffXVV1abNm2sLl26eL1OU3A3bdrUioqK8ipH969Zs2an7FNRadYLa0f3frpcLispKcmUp8d7zZo1hb7HngJc028PHz7catmypTkvEhISzPqrr77q9Z709HTrlltusSpXrmze765bUe11uhTgWr9169ZZbdu2teLi4kxZr7zyyinv37Ztm9WpUyfTtjVq1LAeffRRa+HChaeUWVTdijpmixYtMud/hQoVTHt1797d+uGHH7xeU9j5eLrU5ABQllz6H6cDNQAAfEkSocPG9MawOhQPAAB/Y04SACBoZWZmnpLlbObMmWZ42JVXXulYvQAA4Y2eJABA0Fq2bJkMHTpUbrjhBpPEQec3TZkyxcz/0pui2m9GCwCAv5C4AQAQtDRdtabXfumllzzJBTQ5hiaJIEACAAQKPUkAAAAAYMOcJAAAAACwIUgCAAAAgPI0J0lTxe7evdvcXLCou6EDAAAACH+WZZmbfOtNt/XG6uU2SNIASSf9AgAAAID65ZdfpHbt2lJugyTtQXI3RFJSkoRzj1lqaqq5weLpomL4F+3uHNreGbS7c2h7Z9Duzgj6ds/P14vLE+v6Y3ww1jFc276U0tLSTAeKO0Yot0GSe4idBkjhHiTpTRd1H8PxhA5WtLtzaHtn0O7Ooe2dQbs7I+jbPSNDpEWLE+vp6SIJCRIugr7t/eRM03DCd88BAAAAoAQIkgAAAADAhiAJAAAAAMrTnKTipgLMzc2VvLw8CeXxozk5OWYMaTiPHy2JyMhIiYqKIgU8AAAAiqXcB0nZ2dmyZ88eOXbsmIR6oKeBkuZ9Jxg4VXx8vNSqVUtiYmKcrgoAAACCXLkOkjSo2L59u+lp0BtK6QV0qAYY7t4wekxObRcNhDWVpR7rRo0a0dMGAACA0yrXQZJePGugpLnStachlBEkFa1ChQoSHR0tO3fuNMc8Li7O6SoBAIBQFhUlcu+9J9cRdjiqmr2CnoWwxzEGAAB+ExsrMmGC07VAAHHlCAAAAAA29CQBAAAAvrAskQMHTqxXry7CVIewQ5AEAAAA+EKzIqeknFhPTxdJSHC6RvAzhtuFoNtuu80kZ7j77rtPeW7QoEHmOX1NsNP6a13HjRvn2bZs2TKzrbBl7dq1ntf06NHDpPROSEiQVq1ayRtvvOHgngAAACCcECSFKM3IN3v2bDl+/Lhnm95I9q233pK6detKsJs3b56sXr3apF63++Mf/2juW2Vf7rjjDmnQoIFceOGF5jUrV66UFi1ayHvvvScbN26UAQMGSL9+/eTjjz92aG8AAAAQTgiSCpORUfSSmVn819oCmNO+tgRat25tAqW5c+d6BR4aIP3hD3/weq2mOR81apQJNDQddsuWLeXdd9/1PJ+XlycDBw70PN+4cWMZP368VxnaM9WzZ0/5v//7P9ODU61aNdNrlZOT43Pdf/vtN7n//vtN74+m5rbTe1XVrFnTs+jnfPDBByYQcqc2f/TRR+WZZ54xAdW5554rgwcPli5duni1BQAAAFBSzEkqTMWKRT/XrZvIJ5+cfKzjUXVcamHat9exYScf169/cpJfwcl/JXD77bfLtGnT5NZbbzWPZ8yYYYKZ5cuXe71OA6RZs2bJpEmTzM1UV6xYIX379pXk5GRp3769CaJq164tc+bMMUGJ9tTcddddJhi68cYbPeUsXbrUbNO/W7dulT59+pihbnfeead5/qmnnpLp06fLjh07iqyzftZf/vIXGT58uDRr1uyM+/jhhx/KwYMHTZB0OkeOHJEmTZqcsTwAAIBA0ZvXp6WlBaz8pKQkc/2GwCNICmEa6IwYMcLcJFVvJqvBjQ7BswdJWVlZ8s9//lMWLVokbdu2NdvOOecc+fLLL2Xy5MkmSNLenJEjR3reoz1Kq1atknfeeccrSKpSpYq88sorEhkZKeeff75ce+21snjxYk+QVL16ddOzczrPPfecueHtAw88UKx9nDJlinTu3NkEcUXReup8Jd0fAAAApwKkvgPukENHi/jx3A+qJsbLrGmvEyiVAYKkwmiWkqJERno/3r+/6NcWvIHpaXpYSkL/gWigor032kPTtWtXE6jYaY/PsWPH5Oqrr/banp2d7TUsb8KECTJ16lTZtWuXmeekz2svkZ32/GiA5Ka9St99953n8X333WeWoqxfv94M49uwYYNn6Nzp/Prrr/LZZ5+ZIKgo2qulvUyvvfZasXqmAAAAAkF7kDRASm7bWxKq1vB7+RmH9knqqvfM5xAkBR5BUmF8SeMYqNf6MOTOHZgUnEek0v8X8H3yySdy9tlnez0Xq3eLFjG9Tw899JC8+OKLprcpMTFRXnjhBVmzZo3X6wvOH9JAR4Oz4vriiy9k//79XokldD7Ugw8+aDLcFRymp0MJdfjfn/70p0LL0x6z7t27y9ixY03iBgAAgDIRFSXSv//JdRsNkJJSih4BUxqpASkVhSFICnGasEB7fTRgueaaa055vmnTpiYY0h4iHVpXmK+++sokQbj33ns927Zt2+b3uupcpE6dOnlt06F0ur3gnCMdPqhBkgY/BYMzdxrw6667zgzf0/lTAAAAZUZ/aJ4+3elaIIAIkkKcDn/bvHmzCSrsQ+HctFdIe4mGDh1qen0uu+wyk+RAAyOd/Ne/f3+TzGHmzJlmaJvOR/r3v/9t5vjoui90vpJm2NN5SoXRXiFd7DQA0ix2mlHPbsmSJbJ9+3aT/ruwIXYaIGlWu969e8vevXs9mfGqVq3qU50BAACAgkgBHgY02NGlKJou+/HHHzdZ7jQDnPY+6fA7dxD017/+VXr16mWy1V1yySUmm5y9V6m4Dhw44LceKE3YoL1bmiCiIM3ip/OsdH90XpR70X0AAAAIOM1M7L6VSwmzFCO4uSztgghjOrmtUqVKpvekYCChN1/V3goNFuLi4iSU6WHMzc01meOKkxShvAnUsdbeOZ1nlZKSIhEFE3UgoGh7Z9DuzqHtnUG7OyPo212DI/ctY3T+d0KC+aH4ptvvlvrX3huQOUlp+3+VHZ+8KrOnTjpjNuGwbvsAxgZ24bfnAAAAAFAKBEkAAAAAYEOQBAAAAAA2BEkAAAAAYEOQ9L+kBwhvHGMAAAAUV7kOktw3KdV00ghv7mNc2I1pAQAAALtyfTNZvflq5cqVTZpDFR8fH7Lps0kBXnS7aICkx1iPdWE33AUAAPCJXk/8+c8n1xF2ynWQpGrWrGn+ugOlUA4GNK+95rMnSDqVBkjuYw0AAFAqes/FOXOcrgUCqNwHSRpQ1KpVy9wwKycnR0KVBkgHDx6UatWqheWNv0pDh9jRgwQAAIDiKvdBkpteRIfyhbQGSRoMxMXFESQBAAAApcDVNAAAAOCLjAwdjnRi0XWEHYIkAAAAALAhSAIAAAAAG4IkAAAAALAhSAIAAAAAG4IkAAAAALAhSAIAAAAAG+6TBAAAAPhC763ZrdvJ9TKSk50tO3fuDEjZSUlJkpycHJCyQxFBEgAAAOCLuDiRTz4p04/MSj8iO7b/LEMefUpiY2P9Xn7VxHiZNe11qVatmt/LDkUESQAAAECQy8k6LvmuKKl+aS+pdlY9v5adcWifpK56T9LS0giS/ocgCQAAAAgR8VWSJSmltt/LTfV7iaGNxA0AAACALzIyRBISTiy6jrBDTxIAAADgq2PHnK4BAoieJAAAAACwIUgCAAAAABuCJAAAAACwIUgCAAAAABuCJAAAAACwIbsdAAAA4IuICJH27U+uI+wQJAEAAAC+qFBBZNkyp2uBAAqa0Hf06NHicrlkyJAhnm2ZmZkyaNAgqVatmlSsWFF69+4t+/btc7SeAAAAAMJbUARJa9eulcmTJ0uLFi28tg8dOlQ++ugjmTNnjixfvlx2794tvXr1cqyeAAAAAMKf40FSenq63HrrrfLaa69JlSpVPNuPHDkiU6ZMkTFjxkiHDh2kTZs2Mm3aNFm5cqWsXr3a0ToDAACgHMvIEElOPrHoOsKO43OSdDjdtddeK506dZJnn33Ws339+vWSk5Njtrudf/75UrduXVm1apVceumlhZaXlZVlFre0tDTzNz8/3yzhSvfNsqyw3sdgRLs7h7Z3Bu3uHNreGbS7M4K+3fPzJeLAgf+t5pvHWl+dOuISEZdYfv9ILTciIiIg5ZsyXS5Pm1vB3PalVNz9cjRImj17tmzYsMEMtyto7969EhMTI5UrV/baXqNGDfNcUUaNGiUjR448ZXtqaqqZ4xSu9IBr75ue1PoPCGWDdncObe8M2t05tL0zaHdnBHu7u44dkxq2a0wrI0OOHj0qDRvUk5QEkfjokz/Y+0tUlVjJaNZE6iRFSmU/l18xQSSqQT2zD/v37w/qti8t3cegDpJ++eUXGTx4sCxcuFDi4uL8Vu6IESNk2LBhXj1JderUkeTkZElKSpJw/jLRXwB0P8PxhA5WtLtzaHtn0O7Ooe2dQbs7I+jb3TbETusoCQlmCsnW7Tslt4lIUkKs3z9y9+9Z8u2mzZLULk+yq/i3/LQMkR3bd0piYqKkpKQEd9uXUnHjDseCJB1Op5Fq69atPdvy8vJkxYoV8sorr8hnn30m2dnZcvjwYa/eJM1uV7NmzSLLjY2NNUtBepDD8UDb6QldHvYz2NDuzqHtnUG7O4e2dwbt7oygbndbnUz9dBjc/4ar6UA4ywxg8y8t1wyFC0D5psz/DRc0Q/pcQdz2pVTcfXIsSOrYsaN89913XtsGDBhg5h098sgjpvcnOjpaFi9ebFJ/qy1btsiuXbukbdu2DtUaAAAAQLhzLEjS7rzmzZt7bUtISDD3RHJvHzhwoBk6V7VqVTNU7v777zcBUlFJGwAAAAAg5LPbnc7YsWNNl5j2JGnGus6dO8urr77qdLUAAABQnumQrQsvPLmOsBNUQdKyZctOmVg1YcIEswAAAABBoUIFkUKyMyN8EPoCAAAAgA1BEgAAAADYECQBAAAAvjh2TKR+/ROLriPsBNWcJAAAACDoWZbIzp0n1xF26EkCAAAAABuCJAAAAACwIUgCAAAAABuCJAAAAACwIUgCAAAAABuy2wEAAAC+cLlEmjY9uY6wQ5AEAAAA+CI+XmTTJqdrgQBiuB0AAAAA2BAkAQAAAIANQRIAAADgi2PHRJo1O7HoOsIOc5IAAAAAX1iWyA8/nFxH2KEnCQAAAABsCJIAAAAAwIYgCQAAAABsCJIAAAAAwIYgCQAAAABsyG4HAAAA+MLlEqlX7+Q6wg5BEgAAAOCL+HiRHTucrgUCiOF2AAAAAGBDkAQAAAAANgy3AwAAAHxx/LjIFVecWF+xQqRCBQl1OdnZsnPnTrEsS44ePSrp6eni8uN8q6SkJElOTpZQQZAEAAAA+CI/X2TdupPrIS4r/Yjs2P6zDHn0KYmLi5OGDerJ1u0nAiZ/qZoYL7OmvR4ygRJBEgAAAFCO5WQdl3xXlFS/tJdUP6uepCSI5DYR8VeIlHFon6Suek/S0tIIkgAAAACEjvgqyZKUcrbER2dJUkKsWOK/4XapElpI3AAAAAAANgRJAAAAAGBDkAQAAAAANsxJAgAAAHxVvbrTNUAAESQBAAAAvkhIEEkNtVQE8AXD7QAAAADAhiAJAAAAAGwIkgAAAABfHD8ucuWVJxZdR9hhThIAAADgi/x8keXLT64j7NCTBAAAAAA2BEkAAAAAYEOQBAAAAAA2BEkAAAAAYEOQBAAAAAA2ZLcDAAAAfBUf73QNEEAESQAAAIAvEhJEMjKcrgUCiOF2AAAAAGBDkAQAAAAANgRJAAAAgC8yM0WuvfbEousIO8xJAgAAAHyRlyfy6acn1xF26EkCAAAAABuCJAAAAACwIUgCAAAAABuCJAAAAACwIUgCAAAAABuCJAAAAACwIQU4AAAA4IuEBBHLcroWCCB6kgAAAADAhiAJAAAAAGwIkgAAAABfZGaK3HDDiUXXEXYIkgAAAABf5OWJvPvuiUXXEXYIkgAAAADAhiAJAAAAAGwIkgAAAADAhiAJAAAAAGwIkgAAAADAhiAJAAAAAGyi7A8AAAAAnEF8vEh6+sl1hB2CJAAAAMAXLpdIQoLTtUAAMdwOAAAAAGwIkgAAAABfZGWJ3HbbiUXXEXYIkgAAAABf5OaKzJhxYtF1hB1Hg6SJEydKixYtJCkpySxt27aV+fPne57PzMyUQYMGSbVq1aRixYrSu3dv2bdvn5NVBgAAABDmHA2SateuLaNHj5b169fLunXrpEOHDtKjRw/ZtGmTeX7o0KHy0UcfyZw5c2T58uWye/du6dWrl5NVBgAAABDmHM1u1717d6/H//jHP0zv0urVq00ANWXKFHnzzTdN8KSmTZsmTZo0Mc9feumlDtUaAAAAQDgLmhTgeXl5pscoIyPDDLvT3qWcnBzp1KmT5zXnn3++1K1bV1atWlVkkJSVlWUWt7S0NPM3Pz/fLOFK982yrLDex2BEuzuHtncG7e4c2t4ZtHv4tfuBAwc814cl5Tp2TM793/q2bdvEio+XnTt3Sn5unrj0ebH8Ulevz9QhYBERASn/1LItv36GKdflCop/S8X9fMeDpO+++84ERTr/SOcdzZs3T5o2bSrffPONxMTESOXKlb1eX6NGDdm7d2+R5Y0aNUpGjhx5yvbU1FTzGeFKD/iRI0fMyacnOcoG7e4c2t4ZtLtzaHtn0O7h1e5a5ovjX5b046XLSBebkyPT/rf+7PNjJCs6WrKzsyQpMUFS4vIkKdr/Ge+iqsRKRrMmUicpUir7uXx72VWis6RSZI4JbDRU8oeKCSJRDerJ0aNHZf/+/eIkrUNIBEmNGzc2AZGetO+++67079/fzD8qqREjRsiwYcM8j/WXgjp16khycrJJDhHOXyYaoet+8iVedmh359D2zqDdnUPbO4N2D692T09Pl29++FGSL+0lCVVrlLicyGz94X2GWc89v7PkxsTJgZ+/l2+WTZeKbbOkRlKs+Nvu37Pk202bJaldnmRXiQ1Y2TlVYk0fUmpOrN+CpLQMkR3bd0piYqKkpKSIk+Li4kIjSNLeooYNG5r1Nm3ayNq1a2X8+PHSp08fyc7OlsOHD3v1Jml2u5o1axZZXmxsrFkK0n9g4f7lpl8m5WE/gw3t7hza3hm0u3Noe2fQ7uHT7u4hX/FVa0hiSu2SF2RZMnj8Z2Y1JrGyxLhccvTg3hPDBP3YA+P1ke5hiAEo/9SyXf8bcOefzzHlWpbnmDqpuJ8fdP/a9QDpnCINmKKjo2Xx4sWe57Zs2SK7du0yw/MAAAAAR7hckp5UxSy6jvDjaE+SDo3r2rWrScag4wM1k92yZcvks88+k0qVKsnAgQPN0LmqVauaoXL333+/CZDIbAcAAAAgLIMknbjVr18/2bNnjwmK9MayGiBdffXV5vmxY8eaLjG9iaz2LnXu3FleffVVJ6sMAACAci4qJ1v6zB5n1t++aYjkRsc4XSWEU5Ck90E608SqCRMmmAUAAAAIBhH5edJhybtmfc6N9ztdHQRA0M1JAgAAAAAnESQBAAAAgA1BEgAAAADYECQBAAAAgA1BEgAAAADYECQBAAAAQLCkAAcAAABCTU50rDz8wvuedYQfgiQAAADAB1ZEhBysfpbT1UAAMdwOAAAAAGzoSQIAAAB8EJmbI73em2jW5/a+R/Kiop2uEvyMniQAAADAB5F5udJlwSyz6DrCD0ESAAAAANgQJAEAAABAaYOkn3/+uSRvAwAAAIDwDJIaNmwoV111lcyaNUsyMzP9XysAAAAACKUgacOGDdKiRQsZNmyY1KxZU/7617/Kf/7zH//XDgAAAABCIUhq1aqVjB8/Xnbv3i1Tp06VPXv2yGWXXSbNmzeXMWPGSGpqqv9rCgAAAADBnrghKipKevXqJXPmzJHnnntOtm7dKg899JDUqVNH+vXrZ4InAAAAIJzkRMfK48++ZRZdR/gpVZC0bt06uffee6VWrVqmB0kDpG3btsnChQtNL1OPHj38V1MAAAAgCFgREbL77HPNousIP1EleZMGRNOmTZMtW7ZIt27dZObMmeZvxP9OkgYNGsj06dOlfv36/q4vAAAAAARfkDRx4kS5/fbb5bbbbjO9SIVJSUmRKVOmlLZ+AAAAQFCJzM2Raz+eZtY/uW6A5EVFO10lBEOQ9NNPP53xNTExMdK/f/+SFA8AAAAErci8XOnxwetmfUHXvxAkhaESDaLUoXaarKEg3TZjxgx/1AsAAAAAQidIGjVqlFSvXr3QIXb//Oc//VEvAAAAAAidIGnXrl0mOUNB9erVM88BAAAAQLkKkrTHaOPGjads//bbb6VatWr+qBcAAAAAhE6QdPPNN8sDDzwgS5culby8PLMsWbJEBg8eLDfddJP/awkAAAAAwZzd7plnnpEdO3ZIx44dJSrqRBH5+fnSr18/5iQBAAAAKH9Bkqb3fvvtt02wpEPsKlSoIBdccIGZkwQAAACEs5zoGHnm8emedYSfEgVJbuedd55ZAAAAgPLCioiUHec0dboaCLYgSecgTZ8+XRYvXiz79+83Q+3sdH4SAAAAAJSbIEkTNGiQdO2110rz5s3F5XL5v2YAAABAEIrMzZFOC2eb9UVX3yR5UdFOVwnBECTNnj1b3nnnHenWrZu/6wMAAAAEtci8XLnxnZfN+tIOfyZICkMRJU3c0LBhQ//XBgAAAABCMUh68MEHZfz48WJZlv9rBAAAAAChNtzuyy+/NDeSnT9/vjRr1kyio727GOfOneuv+gEAAABA8AdJlStXluuvv97/tQEAAACAUAySpk2b5v+aAAAAAECozklSubm5smjRIpk8ebIcPXrUbNu9e7ekp6f7s34AAAAAEPw9STt37pQuXbrIrl27JCsrS66++mpJTEyU5557zjyeNGmS/2sKAAAABIGc6Bh5/pGJnnWEn4iS3kz2wgsvlN9//10qVKjg2a7zlBYvXuzP+gEAAABBxYqIlC3ntzGLriP8lKgn6YsvvpCVK1ea+yXZ1a9fX3777Td/1Q0AAAAAQiNIys/Pl7y8vFO2//rrr2bYHQAAABCuInNz5Yrl88z6ivbXS15UiS6pEW7D7a655hoZN26c57HL5TIJG5588knp1q2bP+sHAAAABJXIvBzpO+sFs+g6wk+Jwt4XX3xROnfuLE2bNpXMzEy55ZZb5KeffpLq1avLW2+95f9aAgAAAEAwB0m1a9eWb7/9VmbPni0bN240vUgDBw6UW2+91SuRAwAAAACEmhIPoIyKipK+ffv6tzYAAAAAEIpB0syZM0/7fL9+/UpaHwAAAAAIvSBJ75Nkl5OTI8eOHTMpwePj4wmSAAAAAJSv7HZ6E1n7onOStmzZIpdddhmJGwAAAACENL8ldW/UqJGMHj3azFP673//669iAQAAgKCSGxUt44eM8awj/Pj1zleazGH37t3+LBIAAAAIKvmRUbKx5WVOVwPBFiR9+OGHXo8ty5I9e/bIK6+8Iu3atfNX3QAAAAAgNIKknj17ej12uVySnJwsHTp0MDeaBQAAAMJVZG6uXLp6gVlffWkXyYvy6+AsBIESHdH8/Hz/1wQAAAAIAZF5OXL7lKfN+tqLOhIkhaESZbcDAAAAgHBVorB32LBhxX7tmDEnMn8AAAAAQNgGSV9//bVZ9CayjRs3Ntt+/PFHiYyMlNatW3vNVQIAAACAsA+SunfvLomJiTJjxgypUqWK2aY3lR0wYIBcfvnl8uCDD/q7ngAAAAAQvHOSNIPdqFGjPAGS0vVnn32W7HYAAAAAyl+QlJaWJqmpqads121Hjx71R70AAAAAIHSG211//fVmaJ32Gl188cVm25o1a2T48OHSq1cvf9cRAAAACBq5UdEy8d5/etYRfkoUJE2aNEkeeughueWWW0zyBlNQVJQMHDhQXnjhBX/XEQAAAAga+ZFRsu6iTk5XA8EWJMXHx8urr75qAqJt27aZbeeee64kJCT4u34AAAAAEDo3k92zZ49ZGjVqZAIky7L8VzMAAAAgCEXk5cqFaxeZRdcRfkoUJB08eFA6duwo5513nnTr1s0ESkqH25H+GwAAAOEsKjdH7nn1UbPoOsJPiYKkoUOHSnR0tOzatcsMvXPr06ePLFiwwJ/1AwAAAIDgn5P0+eefy2effSa1a9f22q7D7nbu3OmvugEAAABAaPQkZWRkePUguR06dEhiY2P9US8AAAAACJ0g6fLLL5eZM2d6HrtcLsnPz5fnn39errrqKn/WDwAAAACCf7idBkOauGHdunWSnZ0tDz/8sGzatMn0JH311Vf+ryUAAAAABHNPUvPmzeXHH3+Uyy67THr06GGG3/Xq1Uu+/vprc7+k4ho1apRcdNFFkpiYKCkpKdKzZ0/ZsmWL12syMzNl0KBBUq1aNalYsaL07t1b9u3bV5JqAwAAAID/e5JycnKkS5cuMmnSJPn73/8upbF8+XITAGmglJubK48++qhcc8018sMPP3huTKuZ9D755BOZM2eOVKpUSe677z4TkNFjBQAAACfkRUbL1IFPeNYRfnwOkjT198aNG/3y4QXThU+fPt30KK1fv16uuOIKOXLkiEyZMkXefPNN6dChg3nNtGnTpEmTJrJ69Wq59NJL/VIPAAAAoLjyoqLkq8uuc7oaCLY5SX379jXBy+jRo/1aGQ2KVNWqVc1fDZa056pTp06e15x//vlSt25dWbVqVaFBUlZWllnc0tLSzF9NLKFLuNJ9sywrrPcxGNHuzqHtnUG7O4e2dwbtHl7trmVqwjGXJh4Ty69la5kREREBKTvQ5Z9atuXXzzDlulxB8W+puJ9foiBJh8ZNnTpVFi1aJG3atPEMjXMbM2ZMiSo8ZMgQadeunZnzpPbu3SsxMTFSuXJlr9fWqFHDPFfUPKeRI0eesj01NdXMbwpX2n4aZOrJpyc5ygbt7hza3hm0u3Noe2fQ7uHV7kePHpWGDepJSoJIfPTJH9V9FZGXK402rjXrP7W4SPIjoySqSqxkNGsidZIipXIpyi5KIMu3l10lOksqReaYwEZDJX+omCAS1aCeaf/9+/eLk7QOfg+Sfv75Z6lfv758//330rp1a7NNEzjYaZRYEjo3Scv98ssvpTRGjBghw4YN8+pJqlOnjiQnJ0tSUpKE85eJtr3uJ1/iZYd2dw5t7wza3Tm0vTNo9/Bq9/T0dNm6fafkNhFJSij5vT1jsvKl/4uPmPV7Jy2T7NhY2f17lny7abMktcuT7Cr+v29oIMu3l51TJdb0IaXmxPotSErLENmxfacnWZuT4uLi/B8kNWrUSPbs2SNLly41j/v06SMvvfSS6dkpDU3G8PHHH8uKFSukdu3anu01a9Y0KcYPHz7s1Zuk2e30ucLozWwLu6Gt/gML9y83/TIpD/sZbGh359D2zqDdnUPbO4N2D592dw/5cg8oKyn7e08MTDsxOM0ME/RjD4z3Zwau/FPLdnn2y1/lu4c6Ov3vqLif71Mtdefs5s+fb9J/l5SWpwHSvHnzZMmSJdKgQQOv53UonyaKWLx4sWebpgjftWuXtG3btsSfCwAAAAB+nZNUVNBUkiF2mrnugw8+MN1v7nlGmuq7QoUK5u/AgQPN8DlN5qDD5e6//34TIJHZDgAAAIDjQZLJBlJgzlFJ5yCpiRMnmr9XXnml13ZN833bbbeZ9bFjx5puMb2JrGat69y5s7z66qsl/kwAAAAA8FuQpD1HGry45/xotri77777lOx2c+fOLXZ5xZlcNWHCBLMAAAAAQFAFSf379z/lfkkAAAAAUG6DJB0GBwAAAJRneZHRMqvvcM86wk+pEjcAAAAA5U1eVJQs7XiD09VAAJHwHwAAAABs6EkCAAAAfODKz5PzfvzGrP94XiuxIiKdrhL8jCAJAAAA8EF0TrY8/Nw9Zv2eScslO7aC01WCnzHcDgAAAABsCJIAAAAAwIYgCQAAAABsCJIAAAAAwIYgCQAAAABsCJIAAAAAwIYU4AAAAIAP8iKj5J0b7/esI/xwVAEAAAAf5EVFy2dd/+J0NRBADLcDAAAAABt6kgAAAAAfuPLzpN6OLWZ9Z/3GYkVEOl0l+BlBEgAAAOCD6JxsefyZ28z6PZOWS3ZsBaerBD9juB0AAAAA2BAkAQAAAIANQRIAAAAA2BAkAQAAAIANQRIAAAAA2BAkAQAAAIANKcABAAAAH+RFRskHPe7wrCP8cFQBAAAAH+RFRcuHPe9yuhoIIIbbAQAAAIANPUkAAACAD1z5+VJrz3azvqdWA7Ei6HcINwRJAAAAgA+ic7LkmcduNuv3TFou2bEVnK4S/IywFwAAAABsCJIAAAAAwIYgCQAAAABsCJIAAAAAwIYgCQAAAABsCJIAAAAAwIYU4AAAAIAP8iKjZEGXvp51hB+OKgAAAOCDvKhomdPnAaergQBiuB0AAAAA2NCTBAAAAPjAlZ8vVQ/tNeuHqtYUK4J+h3BDkAQAAAD4IDonS54f3tOs3zNpuWTHVnC6SvAzwl4AAAAAsCFIAgAAAAAbgiQAAAAAsCFIAgAAAAAbgiQAAAAAsCFIAgAAAAAbUoADAAAAPsiPiJQlHf7sWUf4IUgCAAAAfJAbHSNv/OVhp6uBAGK4HQAAAADY0JMEAAAA+MKypOLRw2Y1PbGyiMvldI3gZwRJAAAAgA9isjNl/ODOZv2eScslO7aC01WCnzHcDgAAAABsCJIAAAAAwIYgCQAAAABsCJIAAAAAwIYgCQAAAABsCJIAAAAAwIYU4AAAAIAP8iMi5at213rWEX4IkgAAAAAf5EbHyNQ7nnS6GggghtsBAAAAgA09SQAAAIAvLEtisjPNanZMnIjL5XSN4Gf0JAEAAAA+0ABp4t3tzeIOlhBeCJIAAAAAwIYgCQAAAABsCJIAAAAAwIYgCQAAAABsCJIAAAAAwIYgCQAAAABsuE8SAAAA4IP8iAhZd2EHzzrCD0ESAAAA4IPc6FiZOGi009VAABH6AgAAAECwBEkrVqyQ7t27y1lnnSUul0vef/99r+cty5InnnhCatWqJRUqVJBOnTrJTz/95Fh9AQAAAIQ/R4OkjIwMadmypUyYMKHQ559//nl56aWXZNKkSbJmzRpJSEiQzp07S2ZmZpnXFQAAAFAxWcdlyoCLzaLrCD+Ozknq2rWrWQqjvUjjxo2Txx57THr06GG2zZw5U2rUqGF6nG666aYyri0AAACA8iBoEzds375d9u7da4bYuVWqVEkuueQSWbVqVZFBUlZWllnc0tLSzN/8/HyzhCvdNw0sw3kfgxHt7hza3hm0u3Noe2fQ7uHV7lqmTvFwiYhLrBKXY3+vrp9YRCIiIkpddtGfGbjyTy3b8utnmHJdrqD4t1Tczw/aIEkDJKU9R3b62P1cYUaNGiUjR448ZXtqampYD9PTA37kyBFz8ulJjrJBuzuHtncG7e4c2t4ZtHt4tfvRo0elYYN6kpIgEh998kd1X0XnnXxvclSW5ERHSFSVWMlo1kTqJEVK5VKUXZRAlm8vu0p0llSKzDGBzYnQr/QqJohENahn2n///v3iJK1DSAdJJTVixAgZNmyYV09SnTp1JDk5WZKSkiScv0w0Qtf95Eu87NDuzqHtnUG7O4e2dwbtHl7tnp6eLlu375TcJiJJCbElLicm92RvRGpurGTnxMru37Pk202bJaldnmRXKXnZRQlk+fayc6rEmj6k1JxYvwVJaRkiO7bvlMTERElJSREnxcXFhXaQVLNmTfN33759Jrudmz5u1apVke+LjY01S0H6Dyzcv9z0y6Q87Gewod2dQ9s7g3Z3Dm3vDNo9fNrdPeTLPaCspOzvdQ+2s9zDBP3YA+P9mYEr/9SyXbZBhP4p3z3U0el/R8X9/KD9196gQQMTKC1evNirV0iz3LVt29bRugEAAAAIX472JJkuz61bvZI1fPPNN1K1alWpW7euDBkyRJ599llp1KiRCZoef/xxc0+lnj17OlltAAAAlGP5ERGysUU7zzrCj6NB0rp16+Sqq67yPHbPJerfv79Mnz5dHn74YXMvpbvuuksOHz4sl112mSxYsKDYYwkBAAAAf8uNjpXxQ8c6XQ2Ea5B05ZVXmvGJRdFxi08//bRZAAAAAKAs0D8IAAAAADYESQAAAIAPYrKOy6t/vcIsuo7wE7QpwAEAAIBgFZud6XQVEED0JAEAAACADUESAAAAANgQJAEAAACADUESAAAAANgQJAEAAACADdntAAAAAB9YLpf8t3FrzzrCD0ESAAAA4IOcmDh54W+TnK4GAojhdgAAAABgQ5AEAAAAADYESQAAAIAPYrKOy7j7rzGLriP8MCcJAAAA8FFi+mGnq4AAoicJAAAAAGwIkgAAAADAhiAJAAAAAGwIkgAAAADAhiAJAAAAAGzIbgcAAAD4wHK5ZHv9Jp51hB+CJAAAAMAHOTFx8uyTM5yuBgKI4XYAAAAAYEOQBAAAAAA2BEkAAACAD2KyMuW5h3qYRdcRfpiTBAAAAPjEkuoH93jWEX7oSQIAAAAAG4IkAAAAALAhSAIAAAAAG4IkAAAAALAhSAIAAAAAG7LbAQAAAD5xyW9nNfCsI/wQJAEAAAA+yI6Nkyf+8bbT1UAAMdwOAAAAAGwIkgAAAADAhiAJAAAA8EFMVqY8/fc+ZtF1hB/mJAEAAAA+seTs3ds96wg/9CQBAAAAgA1BEgAAAADYECQBAAAAgA1BEgAAAADYECQBAAAAgA3Z7QAAAACfuORAtVqedYQfgiQAAADAB9mxcfLI/33gdDUQQAy3AwAAAAAbgiQAAAAAsGG4HQAAAOCD6OxMeWTUX836cyMmS05MnNNVgp8RJAEAAAA+cFmWNNix2bOO8MNwOwAAAACwIUgCAAAAABuCJAAAAACwIUgCAAAAABuCJAAAAACwIbsdAAAA4KOjFSs7XQUEEEESAAAA4IPs2Aoy5OXPna4GAojhdgAAAABgQ5AEAAAAADYMtwMAAAB8EJ2dKUPGDDHr44aNk5yYOKerBD8jSAKAMJOamippaWkBKTsxMTEg5YaDQLZ7UlKSVKtWLSBlI3zPmeTkZAmU8n6+uyxLzt+ywbOO8EOQBABhRC9c+g64Qw4dPRaQ8qslJcj4/3tOUlJSAlJ+qAp0u1dNjJd/T30tIGUjfM+ZWdNeD0igxPmO8oAgCQDCiP6yqxcuyW17S0LVGn4tO+PQPjmweq4cOxaYC6NQFuh2T131nvmMihUr+rVshP85E4ggifMd5QFBEgCEIb1wSUqp7fdyD/i9xPASqHZP9XuJCBahfM6Ect2BMyG7HQAAAADYECQBAAAAgA3D7QAAAAAfZZH2O6wRJAEAAAA+yI6tIPdOXuF0NRBADLcDAAAAABt6kspYoG6+ZlmWHD16VCIiIgJ2/5JA3jiuLG58F0gHDhww7R8IodwuoXxT01C+ySPK/pju3LlTcnNyJVRxvoefnOxsc14GQqif70BxECSVoUDefM3lcknDBvXk0IFUcwM2f/8PKdA3jgv0je8C6ciRIzL4oUfkYFpGQMoP1XYJ5ZuahvJNHuHMMc08fkx+/W2P1M3JkVDD+R5+stKPyI7tP8uQR5+S2NhYv5cfyue7v0TlZMmgV/5m1ifcN1pyo/3fznAWQVIZCuTN11wiUsk6LFvnvxWQm8cFsu5lceO7QNIba4bqDQEDKZRvahrKN3mEM99h+7d9Lzt/mSp5uaF30cj5Hn5yso5LvitKql/aS6qdVc/v5Yfy+e4vEfn50mLjV551hB+CJAcE4uZrLrEkNjAdGWVy47hwuHkcN9ULv5uackzDT6COafrBvRLqON/DT3yVZM53oIRI3AAAAAAAoRYkTZgwQerXry9xcXFyySWXyH/+8x+nqwQAAAAgTAV9kPT222/LsGHD5Mknn5QNGzZIy5YtpXPnzrJ//36nqwYAAAAgDAV9kDRmzBi58847ZcCAAdK0aVOZNGmSxMfHy9SpU52uGgAAAIAwFNSJG7Kzs2X9+vUyYsQIzza9D1CnTp1k1apVhb4nKyvLLPb0zOrw4cOS73D2Ec3uk5+XJ0f27JDczGN+z24n1hHJycyUTZs2+f1+F7/88ovkZGUFpO4q4/f9Aat7oG3fvj1gbRPK7RLIc8bdLtr2oVr3QB3TUG73QAr0d9jR1F/N9/DRfb9ItPlCDsw5U6VKFdmzZ49fyw/l872s6H3wQqndA3k+Brr8UDnfY7IzxX1GH/rlJ8mOiQvpdreXHeMSiYkXOXRMxPLjcdVrYP0e0GtyJ7m/i/Qeo6fjss70Cgft3r1bzj77bFm5cqW0bdvWs/3hhx+W5cuXy5o1a055z1NPPSUjR44s45oCAAAACBUaMNeuXTs0e5JKQnuddA6Tm/YeHTp0SKpVq2ZuuBquNCquU6eOOeB6d3OUDdrdObS9M2h359D2zqDdnUG7Oyfc296yLNM7fNZZZ532dUEdJFWvXl0iIyNl3759Xtv1cc2aNQt9j95ZuuDdpStXrizlhZ7M4XhCBzva3Tm0vTNod+fQ9s6g3Z1BuzsnKYzbvlKlSqGduCEmJkbatGkjixcv9uoZ0sf24XcAAAAA4C9B3ZOkdOhc//795cILL5SLL75Yxo0bJxkZGSbbHQAAAACUuyCpT58+kpqaKk888YTs3btXWrVqJQsWLJAaNWo4XbWgokMM9V5SBYcaIrBod+fQ9s6g3Z1D2zuDdncG7e4c2j4EstsBAAAAQFkL6jlJAAAAAFDWCJIAAAAAwIYgCQAAAABsCJIAAAAAwIYgKYitWLFCunfvbu4I7HK55P333/d6/rbbbjPb7UuXLl28XnPo0CG59dZbzc3A9Ka6AwcOlPT09DLek9AyatQoueiiiyQxMVFSUlKkZ8+esmXLFq/XZGZmyqBBg6RatWpSsWJF6d279yk3Pd61a5dce+21Eh8fb8oZPny45ObmlvHehF/bX3nllaec93fffbfXa2h730ycOFFatGjhuXGg3odu/vz5nuc5351re873sjF69GjTtkOGDPFs47x3pt055wPjqaeeOqVdzz//fM/znO+nIkgKYno/qJYtW8qECROKfI0GRXv27PEsb731ltfzGiBt2rRJFi5cKB9//LEJvO66664yqH3oWr58ufmiWL16tWm3nJwcueaaa8zxcBs6dKh89NFHMmfOHPP63bt3S69evTzP5+XlmS+S7OxsWblypcyYMUOmT59uUtmjdG2v7rzzTq/z/vnnn/c8R9v7rnbt2uZiZf369bJu3Trp0KGD9OjRw3x3KM5359pecb4H1tq1a2Xy5MkmWLXjvHem3RXnfGA0a9bMq12//PJLz3Oc74XQFOAIfnqo5s2b57Wtf//+Vo8ePYp8zw8//GDet3btWs+2+fPnWy6Xy/rtt98CWt9wsn//ftOOy5cvN48PHz5sRUdHW3PmzPG8ZvPmzeY1q1atMo8//fRTKyIiwtq7d6/nNRMnTrSSkpKsrKwsB/YiPNpetW/f3ho8eHCR76Ht/aNKlSrW66+/zvnuYNsrzvfAOnr0qNWoUSNr4cKFXm3Nee9MuyvO+cB48sknrZYtWxb6HOd74ehJCnHLli0zXZ6NGzeWe+65Rw4ePOh5btWqVWaI3YUXXujZ1qlTJ4mIiJA1a9Y4VOPQc+TIEfO3atWq5q/+4qs9HNqWbtplXbduXdPmSv9ecMEFXjc97ty5s6SlpXn9Qgzf2t7tjTfekOrVq0vz5s1lxIgRcuzYMc9ztH3p6K+Fs2fPNr13OvSL8925tnfjfA8c7bnWX8ft57fivHem3d045wPjp59+MlM4zjnnHDPSSIfPKc73wkUVsR0hQIfaaVdogwYNZNu2bfLoo49K165dzYkcGRkpe/fuNQGUXVRUlLng1OdwZvn5+WasdLt27cyXtdK2i4mJMQGonX5xuNtV/9q/SNzPu59Dydpe3XLLLVKvXj3zRb9x40Z55JFHzLyluXPnmudp+5L57rvvzIW5jkvX8ejz5s2Tpk2byjfffMP57lDbK873wNGAdMOGDWbYV0F8zzvT7opzPjAuueQSMzxOf1TXoXYjR46Uyy+/XL7//nvO9yIQJIWwm266ybOu0b2O6z333HNN71LHjh0drVs4/dqlXyD2cbtwtu3tc+r0vK9Vq5Y53/WHAj3/UTL6P04NiLT37t1335X+/fubcelwru01UOJ8D4xffvlFBg8ebOY+xsXFOV2dcqM47c45Hxj6I7qbXi9q0KTB6DvvvCMVKlRwtG7BiuF2YUS7T7V7euvWreZxzZo1Zf/+/V6v0SwkmvFOn8Pp3XfffSbZxdKlS83kajdtO524ePjwYa/XaxYYd7vq34JZYdyPafuSt31h9Ite2c972t53+itiw4YNpU2bNibLoCaNGT9+POe7g21fGM53/9DhRfr/x9atW5sRFrpoYPrSSy+Zdf2FnPO+7Ntdh5wWxDkfGNprdN5555l25Xu+cARJYeTXX381c5L0Vxelwzf0hNcvJbclS5aYYUzuLx2cSvNk6EW6DnnR9tLhjHZ6IRMdHS2LFy/2bNOhADq21z2PQP/qEBp7kKq/nGmKX/cwGvje9oXRX+CV/byn7UtPvyeysrI43x1s+8JwvvuH9kxou2l7uhedv6vzNNzrnPdl3+46VaAgzvnA0NvBaO+ctivf80UoIqEDgiT7y9dff20WPVRjxowx6zt37jTPPfTQQybryPbt261FixZZrVu3NtliMjMzPWV06dLF+sMf/mCtWbPG+vLLL83zN998s6P7Fezuueceq1KlStayZcusPXv2eJZjx455XnP33XdbdevWtZYsWWKtW7fOatu2rVnccnNzrebNm1vXXHON9c0331gLFiywkpOTrREjRji0V+HR9lu3brWefvpp0+Z63n/wwQfWOeecY11xxRWeMmh73/3tb38zGQS1TTdu3GgeaxbMzz//3DzP+e5M23O+l62CWdU478u+3TnnA+fBBx80/2/Vdv3qq6+sTp06WdWrVzdZZBXn+6kIkoLY0qVLTXBUcNHU33rRqCeqnqCatrFevXrWnXfe6ZWaUR08eNAERRUrVjRpGgcMGGACLBStsDbXZdq0aZ7XHD9+3Lr33ntNqt74+Hjr+uuvNxfzdjt27LC6du1qVahQwXwR6RdUTk6OA3sUPm2/a9cu8z/LqlWrWrGxsVbDhg2t4cOHW0eOHPEqh7b3ze23326+Q2JiYsx3SseOHT0BkuJ8d6btOd+dDZI478u+3TnnA6dPnz5WrVq1zHfN2WefbR5rUOrG+X4ql/6nqF4mAAAAAChvmJMEAAAAADYESQAAAABgQ5AEAAAAADYESQAAAABgQ5AEAAAAADYESQAAAABgQ5AEAAAAADYESQAAAABgQ5AEACHA5XLJ+++/H/DPufLKK2XIkCESDnbs2GHa7ZtvvvH5vYsXL5YmTZpIXl5esV5fv359GTdunJR3f/vb3+T+++93uhoAUGoESQDgsL1795oLy3POOUdiY2OlTp060r17d3OhHs6BiD/ddttt0rNnT7+V9/DDD8tjjz0mkZGREuqeeuopadWqVZl81kMPPSQzZsyQn3/+uUw+DwAChSAJABwOMtq0aSNLliyRF154Qb777jtZsGCBXHXVVTJo0CCnq1cuffnll7Jt2zbp3bu3o/XIzs6WYFKc+lSvXl06d+4sEydOLJM6AUCgECQBgIPuvfde0xPzn//8x1yUn3feedKsWTMZNmyYrF692uu1Bw4ckOuvv17i4+OlUaNG8uGHH3qemz59ulSuXNnr9To8T8su2KPw73//2wwPq1Spktx0001y9OjRIuv3ySefmNe98cYbJdq//Px8GTVqlDRo0EAqVKggLVu2lHfffdfz/LJly0wdtdfswgsvNPv2xz/+UbZs2eJVzrPPPispKSmSmJgod9xxhxnW5e4d0f3S3osPPvjAlKWLluumvRoadGrZ+vmrVq06bZ1nz54tV199tcTFxXlt/+ijj+Siiy4y2zUY0GNhd+zYMbn99ttNHevWrSv/+te/vJ5/5JFHzPHVemiv4eOPPy45OTmnHJ/XX3/dtJf78zVovuyyy8zxrVatmlx33XUmiLP79ddf5eabb5aqVatKQkKCacs1a9aY82LkyJHy7bffetpGt6nDhw+btkxOTpakpCTp0KGDed2Z6qPH74ILLjDHU+vTqVMnycjI8LxPe0G1DQEglBEkAYBDDh06ZC6AtcdIL2wLKhj06MXujTfeKBs3bpRu3brJrbfeasrwhV5ca/D08ccfm2X58uUyevToQl/75ptvmgtvDZD0s0pCA6SZM2fKpEmTZNOmTTJ06FDp27ev+Vy7v//97/Liiy/KunXrJCoqygQbbvr5//jHP+S5556T9evXmwDE3lOhQ7y0Xbp06SJ79uwxiwZa9rL1NTokUIMU3afc3Nwi6/zFF1+YIKNgsKhBkbb7119/bYK6iy++2Os1Wn99nz6vwe8999zjFexp8KQByg8//CDjx4+X1157TcaOHetVxtatW+W9996TuXPneoYwagCiQbO2jX5uRESEqYsGoCo9PV3at28vv/32mwmcNdDR4YL6fJ8+feTBBx80gbe7bXSbuuGGG2T//v0yf/58066tW7eWjh07ep1TBeuj79f20+OzefNmE4z26tVLLMvyvEfbRYM27SUFgJBlAQAcsWbNGr2ytObOnXvG1+rrHnvsMc/j9PR0s23+/Pnm8bRp06xKlSp5vWfevHnmNW5PPvmkFR8fb6WlpXm2DR8+3Lrkkks8j9u3b28NHjzYeuWVV0x5y5YtO229tm/fbj7j66+/PuW5zMxM83krV6702j5w4EDr5ptvNutLly4171+0aJHn+U8++cRsO378uHms9Rs0aJBXGe3atbNatmzpedy/f3+rR48ehdbt9ddf92zbtGmT2bZ58+Yi90n3e+bMmV7b2rZta916661FvqdevXpW3759PY/z8/OtlJQUa+LEiUW+54UXXrDatGnjdXyio6Ot/fv3W6eTmppq9uG7774zjydPnmwlJiZaBw8eLPT1Wq69rdQXX3xhJSUlmWNkd+6555ryiqrP+vXrzWfv2LGjyPodOXLEvOZM5w4ABLMop4M0ACiv7L++F0eLFi0869rzpEOktCfAFzrMTns03GrVqnVKGTqcSrd99dVXZnhZSWkvhA5B06FrBee2/OEPfyhy37ROSuugvUbaG6M9M3baW6HzuIqjqLLPP//8Ql9//PjxU4baaS/KnXfeWezP0WFtNWvW9Grbt99+W1566SXTm6e9P9qbpcfQrl69emb4m91PP/0kTzzxhBk+p0Mu3T1Iu3btkubNm5u6aXvqULvi0t4mrYMOlyu47/ahfAXro8MVtbdJh9vp3KNrrrlG/vznP0uVKlU8r9FheEqPPQCEKoIkAHCIzivSi+n//ve/xXp9dHS012N9r/uCWYdgFQy67PNdilOGm15wb9iwQaZOnWqGj9nnNflCL8LdQ9XOPvtsr+c0i19R9XJ/XsF6lZSvZet8o99//91rm/vCv7if4/4s9+foPCgdsqhDJjW40HleOm9Hh+jZFTbsUuf4aLCiw/POOussU6YGR+5ECsWpW2HHRgNG+9ytwoZ5FqyPZvtbuHChrFy5Uj7//HN5+eWXzXBGDeB03pJyD9crGOwBQChhThIAOER/+dcL5gkTJnhNfHfTifXFpRekmoDBXk5J03Kfe+65snTpUpMIoTT3vGnatKkJhrTHo2HDhl6LpjkvrsaNG8vatWu9thV8HBMTU+x7Gp2JBok6b6hgL1FpUrJrUKGBjgYUGnhqgLxz584zvu/gwYOmJ03TkWsPjt67qWAAp3XTY13U/LTC2kbnH2nqeZ3/VfDYaJB4Ohr8tWvXzgR8Ov9Ky583b57n+e+//94EjDoPCgBCFT1JAOAgDZD0glOHjz399NPmgleHYemv9ZqcQCfHF8cll1xisqY9+uij8sADD3gym5WUJjjQQElvLqsX0me6UWrBbHRKL5I1YYIma9DeD83QduTIETOMT4eZ9e/fv1h10UBNh7ppcKEJGXTYmiav0Axx9mGEn332mamHDiHTnpqS0sBVs+XZPfnkkyZI0QBSMwLqMfr0009Nxrri0KBIg0XtPdIhjNq7Zg8siqLD2HR/NFOe9vxoGZrZz04TKfzzn/8094nSRBn6Og1etNepbdu2pm22b99uAqnatWub4ZaakU6f0/c8//zz5njv3r3bk6CiYOIKNz2vNFjUYXaabVAfp6ammuDNnvji8ssvL1EPFwAEC3qSAMBBeqGvQ9s0RbVmIdNhVDqHRy9EfbnXjPZKzZo1y1y463yRt956y6RwLg3twdF5P1qW1u10NHDQHhj7sm/fPnnmmWdMqmu9eNcLac1Apxfi7qFZxaHD1EaMGGECLu0B0Qt+vXmsfd6QBlFaX7241141DcRKSj9PM/HZAz8NFufMmWOyx2labE2XrWnbi+tPf/qTCRbvu+8+837tWdJ2ORMdRqmBlWaf03NDy9D7adlpT44OfdOgRbPv6fHXjIXuG+Fqanltdz3HtG30eGpvkJ4rV1xxhQwYMMAESXoMtXerRo0aRdZHg9sVK1aYz9H3aA+XDhns2rWr5zVa3zPN3wKAYOfS7A1OVwIAAF9oIKmJEfSeT4EwfPhwSUtLk8mTJwek/HCl6cQ1oNaePu2BBIBQxTcYACCoaZY0vc+SDoPT3hHtCVm0aJEZkhgoOnfo1VdfNcMEtTcHxaNz4qZNm0aABCDk0ZMEAAhqmpZaM7zpPJvMzEwzrE6HeelNTAEACASCJAAAAACwYQwBAAAAANgQJAEAAACADUESAAAAANgQJAEAAACADUESAAAAANgQJAEAAACADUESAAAAANgQJAEAAACAnPT/V18tSSPu28kAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Step 3: Creating vector store...\n",
      "Creating vector store with 169 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vector store created: research_papers\n",
      "\n",
      "üìä Step 4: Initializing BM25...\n",
      "‚úÖ BM25 index created with 169 documents\n",
      "\n",
      "‚öôÔ∏è  Step 5: Creating RAG chain...\n",
      "\n",
      "======================================================================\n",
      "TESTING QUERIES\n",
      "======================================================================\n",
      "\n",
      "üîé Query 1: What is the main contribution of this paper?\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üí° Answer:\n",
      "Unfortunately, I don't have enough information to determine which specific paper you are referring to. The context provided includes multiple papers and sections, but it's not clear which one you're asking about.\n",
      "\n",
      "Could you please specify which paper or section you'd like me to focus on? For example, is it the QANet paper (Rowan Zellers et al., 2018), the SWAG paper (Ronan Collobert and Jason Weston, 2008), or another one?\n",
      "\n",
      "Once I know which paper you're interested in, I'll do my best to summarize its main contribution.\n",
      "\n",
      "‚è±Ô∏è  Time: 13.94s\n",
      "\n",
      "üìà Faithfulness: 0.50\n",
      "\n",
      "üìö Sources (5):\n",
      "   1. neural networks? In Advances in neural information\n",
      "processing systems, pages 3320‚Äì3328.\n",
      "Adams Wei Yu...\n",
      "   2. preprint arXiv:1312.3005.\n",
      "Z. Chen, H. Zhang, X. Zhang, and L. Zhao. 2018.\n",
      "Quora question pairs.\n",
      "Chri...\n",
      "   3. ods in Natural Language Processing, pages 1914‚Äì\n",
      "1925.\n",
      "Ronan Collobert and Jason Weston. 2008. A uniÔ¨Å...\n",
      "   4. Dev\n",
      "Test\n",
      "ESIM+GloVe\n",
      "51.9 52.7\n",
      "ESIM+ELMo\n",
      "59.1 59.2\n",
      "OpenAI GPT\n",
      "-\n",
      "78.0\n",
      "BERTBASE\n",
      "81.6\n",
      "-\n",
      "BERTLARGE\n",
      "86.6 8...\n",
      "   5. for grounded commonsense inference. In Proceed-\n",
      "ings of the 2018 Conference on Empirical Methods\n",
      "in ...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üîé Query 2: What datasets were used?\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üí° Answer:\n",
      "Based on the provided context, the following datasets were mentioned:\n",
      "\n",
      "1. SQuAD v1.1 (Stanford Question Answering Dataset) - a collection of 100k crowd-sourced question/answer pairs (Rajpurkar et al., 2016)\n",
      "2. GLUE dataset\n",
      "3. ImageNet (mentioned in the context of computer vision research, specifically for fine-tuning pre-trained models)\n",
      "\n",
      "Additionally, the following datasets were mentioned as examples of large datasets that are less sensitive to hyperparameter choice:\n",
      "\n",
      "* 100k+ labeled training examples\n",
      "\n",
      "Note that there is no explicit mention of other specific datasets used in the papers.\n",
      "\n",
      "‚è±Ô∏è  Time: 10.71s\n",
      "\n",
      "üìà Faithfulness: 0.50\n",
      "\n",
      "üìö Sources (5):\n",
      "   1. ‚Ä¢ Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
      "‚Ä¢ Number of epochs: 2, 3, 4\n",
      "We also observed that large dat...\n",
      "   2. size is explored more thoroughly in Section 5.2.\n",
      "4.2\n",
      "SQuAD v1.1\n",
      "The\n",
      "Stanford\n",
      "Question\n",
      "Answering\n",
      "Data...\n",
      "   3. 2.3\n",
      "Transfer Learning from Supervised Data\n",
      "There has also been work showing effective trans-\n",
      "fer fro...\n",
      "   4. neural networks? In Advances in neural information\n",
      "processing systems, pages 3320‚Äì3328.\n",
      "Adams Wei Yu...\n",
      "   5. Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke\n",
      "Zettlemoyer. 2017. Triviaqa: A large scale distan...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üîé Query 3: What are the key findings?\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üí° Answer:\n",
      "Based on the provided context, here are the key findings:\n",
      "\n",
      "* Large-scale pre-training of models leads to significant improvements in various natural language processing tasks.\n",
      "* Scaling up model sizes can lead to large improvements on small-scale tasks, as long as the model has been sufficiently pre-trained (Peters et al., 2018b).\n",
      "* Fine-tuning a pre-trained BERT model with a large size (BERTLARGE) outperforms fine-tuning it with a smaller size (BERTBASE) in CoNLL-2003 Named Entity Recognition task, achieving scores of 96.6 and 92.8 respectively.\n",
      "* Feature-based approaches using BERT embeddings or hidden layer representations can achieve competitive results on the same task, with some configurations outperforming fine-tuning.\n",
      "\n",
      "Note that these findings are based on specific papers and tasks mentioned in the context, and may not be generalizable to all natural language processing tasks.\n",
      "\n",
      "‚è±Ô∏è  Time: 13.35s\n",
      "\n",
      "üìà Faithfulness: 1.00\n",
      "\n",
      "üìö Sources (5):\n",
      "   1. 2018). These include sentence-level tasks such as\n",
      "natural language inference (Bowman et al., 2015;\n",
      "W...\n",
      "   2. datasets, the descriptions of which were originally\n",
      "summarized in Wang et al. (2018a):\n",
      "MNLI\n",
      "Multi-Ge...\n",
      "   3. by the LM perplexity of held-out training data\n",
      "shown in Table 6.\n",
      "However, we believe that\n",
      "this is th...\n",
      "   4. news headlines and other sources (Cer et al.,\n",
      "2017). They were annotated with a score from 1\n",
      "to 5 de...\n",
      "   5. CVT (Clark et al., 2018)\n",
      "-\n",
      "92.6\n",
      "CSE (Akbik et al., 2018)\n",
      "-\n",
      "93.1\n",
      "Fine-tuning approach\n",
      "BERTLARGE\n",
      "96.6\n",
      "...\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "results = test_rag_pipeline(\n",
    "    pdf_path='../data/raw/bert.pdf',\n",
    "    test_queries=[\n",
    "        'What is the main contribution of this paper?',\n",
    "        'What datasets were used?',\n",
    "        'What are the key findings?'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da0dbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
